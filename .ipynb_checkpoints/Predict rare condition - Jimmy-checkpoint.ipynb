{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read files into dataframe\n",
    "train_df = pd.read_csv(\"./data/health-diagnostics-train.csv\", na_values=[\"#NULL!\"])\n",
    "test_df = pd.read_csv(\"./data/health-diagnostics-test.csv\", na_values=[\"#NULL!\"])\n",
    "# test_sample = pd.read_csv(\"./data/health-diagnostics-test-sample-solution.csv\")\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "# Replace missing values with mode and change objects to integers\n",
    "def replace_nulls(df):\n",
    "    for f in feature_cols:\n",
    "        df[f] = df[f].astype(float)\n",
    "        df[f].fillna(df[f].mode()[0], inplace=True)\n",
    "        df[f] = df[f].astype(int)\n",
    "\n",
    "replace_nulls(test_df)\n",
    "replace_nulls(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domain:**\n",
    "- income - an annual per capita income of a patient\n",
    "- maternal - maternal delivery age\n",
    "- fam-history - a family history\n",
    "- mat-illness-past - a previous maternal illness history\n",
    "- suppl - nutrition and folic acid supplementation\n",
    "- mat-illness - a maternal illness\n",
    "- meds - medication use\n",
    "- env - an environmental exposures of risk factors\n",
    "- lifestyle - an unhealthy lifestyle\n",
    "- target - a congenital disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.shape\n",
    "# train_df.dtypes\n",
    "# train_df.isnull().sum()\n",
    "# train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for f in feature_cols:\n",
    "# #     display(f, train_df[f].value_counts())\n",
    "#     train_df[f].sort_values().value_counts(sort=False).plot(kind=\"bar\")\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- income\n",
    "    - even distribution\n",
    "- maternal\n",
    "    - large mode of 0\n",
    "- fam-history\n",
    "    - large mode of 0\n",
    "- mat-illness-past\n",
    "    - large mode of 0\n",
    "- suppl\n",
    "    - left skewed\n",
    "- mat-illness\n",
    "- meds\n",
    "- env\n",
    "    - has a distribution\n",
    "- lifestyle\n",
    "    - has a distribution, may need to create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shows binary classification (0 or 1), so requires logistic regression\n",
    "- shows there is a class imbalance, very few 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find train to test ratio\n",
    "train_df.shape[0] / (train_df.shape[0]+test_df.shape[0])\n",
    "\n",
    "# Find percentage of 1's\n",
    "round(train_df['target'].sum() / train_df['target'].count() * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shows there is a 90 : 10 split between train : test\n",
    "- therefore, probably very few true predictions\n",
    "- there is there is 0.18% chance of target 1 for every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_mask = train_df['target'] == 1\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "# Find percentage of 1 occuring out of total for each column each category\n",
    "for f in feature_cols:\n",
    "    display(f, train_df[target_mask][f].value_counts(sort=False), train_df[f].value_counts(sort=False),\n",
    "            train_df[target_mask][f].value_counts(sort=False) / train_df[f].value_counts(sort=False) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_rmse(df, feature_cols):\n",
    "#     X = df[feature_cols]\n",
    "#     y = df.target\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    \n",
    "#     linreg = LinearRegression()\n",
    "#     linreg.fit(X_train, y_train)\n",
    "    \n",
    "#     y_pred = linreg.predict(X_test)\n",
    "#     return np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# print(train_test_rmse(train_df, feature_cols, ['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Displaying confusion matrix\n",
    "display(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "recall_metric = round(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1]),0)\n",
    "print(\"Recall metric in the train dataset: {0}%\".format(recall_metric))\n",
    "\n",
    "# Finding the f1 score\n",
    "display(metrics.f1_score(y_test, y_pred, average=\"binary\"))\n",
    "\n",
    "# Predicting on test data\n",
    "test_df['target'] = logreg.predict(test_df[feature_cols])\n",
    "\n",
    "# Saving to csv for submission\n",
    "test_df['target'].to_csv(\"./data/logreg.csv\", index_label=\"index\", header=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.58 AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Feature engineering\n",
    "train_df['low_income'] = train_df['income'] == 1  # higher chance of target\n",
    "train_df['low_suppl'] = train_df['suppl'] < 2  # higher chance of target\n",
    "train_df['mat_ill_cat'] = train_df['mat-illness'] == 2   # higher chance of target\n",
    "lx_dummies = pd.get_dummies(train_df['lifestyle'], prefix=\"lx\")\n",
    "lx_dummies.drop(lx_dummies.columns[0], axis=1, inplace=True)\n",
    "train_df = pd.concat([train_df, lx_dummies], axis=1)\n",
    "\n",
    "feature_cols = ['low_income', 'maternal', 'fam-history', 'mat-illness-past', 'low_suppl', 'mat_ill_cat', \n",
    "                'meds', 'lx_1', 'lx_2', 'lx_3', 'lx_4', 'lx_5', 'lx_6', 'lx_7', 'lx_8']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Displaying confusion matrix\n",
    "display(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "recall_metric = round(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1]),0)\n",
    "print(\"Recall metric in the train dataset: {0}%\".format(recall_metric))\n",
    "\n",
    "metrics.f1_score(y_test, y_pred, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- no improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binary classification with unbalanced data\n",
    "\n",
    "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-106\n",
    "https://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-nearest neighbour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Displaying confusion matrix\n",
    "display(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "# recall_metric = round(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1]),0)\n",
    "# print(\"Recall metric in the train dataset: {0}%\".format(recall_metric))\n",
    "\n",
    "metrics.f1_score(y_test, y_pred, average=\"binary\")\n",
    "\n",
    "# scores = []\n",
    "\n",
    "# for k in range(1,10):\n",
    "#     knn = KNeighborsClassifier(n_neighbors=k)\n",
    "#     knn.fit(X_train, y_train)\n",
    "#     y_pred = knn.predict(X_test)\n",
    "#     scores.append([k, metrics.f1_score(y_test, y_pred, average=\"binary\")])\n",
    "\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntheic Minority Over-sampling Technique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "print(\"Before oversampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before oversampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After oversampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After oversampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "print(\"After oversampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After oversampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "\n",
    "parameters = {\n",
    "    'C': np.linspace(1, 10, 10)\n",
    "             }\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters, cv=5, verbose=5, n_jobs=3)\n",
    "clf.fit(X_train_res, y_train_res.ravel())\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression(C=2, penalty='l1', verbose=5)\n",
    "lr1.fit(X_train_res, y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "y_train_pre = lr1.predict(X_train)\n",
    "\n",
    "cnf_matrix_tra = confusion_matrix(y_train, y_train_pre)\n",
    "\n",
    "print(\"Recall metric in the train dataset: {}%\".format(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1])))\n",
    "\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_tra , classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = lr1.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pre)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: {}%\".format(100*cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1])))\n",
    "#print(\"Precision metric in the testing dataset: {}%\".format(100*cnf_matrix[0,0]/(cnf_matrix[0,0]+cnf_matrix[1,0])))\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix , classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = lr1.fit(X_train_res, y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sample_score = tmp.decision_function(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_sample_score)\n",
    "\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "# Plot ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.3f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1.fit(X_train_res, y_train_res.ravel())\n",
    "\n",
    "# Predicting on test data\n",
    "test_df['target'] = lr1.predict(test_df[feature_cols])\n",
    "\n",
    "# Saving to csv for submission\n",
    "test_df['target'].to_csv(\"./data/logreg_smote.csv\", index_label=\"index\", header=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "print(\"Before oversampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before oversampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After oversampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After oversampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "print(\"After oversampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After oversampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "\n",
    "parameters = {\n",
    "    'C': np.linspace(1, 10, 10)\n",
    "             }\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "clf = GridSearchCV(lr, parameters, cv=5, verbose=5, n_jobs=3)\n",
    "clf.fit(X_train_res, y_train_res.ravel())\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "\n",
    "# Read files into dataframe\n",
    "train_df = pd.read_csv(\"./data/health-diagnostics-train.csv\", na_values=[\"#NULL!\"])\n",
    "test_df = pd.read_csv(\"./data/health-diagnostics-test.csv\", na_values=[\"#NULL!\"])\n",
    "\n",
    "# Change nulls to arbitary number and change dtype to integers\n",
    "def replace_nulls(df):\n",
    "    for f in df.columns:\n",
    "        if df[f].dtype != \"int\":\n",
    "            df[f].fillna(-999, inplace=True)    # instead of changing to mode, xgboost can handle missing values\n",
    "            df[f] = df[f].astype(int)\n",
    "\n",
    "replace_nulls(test_df)\n",
    "replace_nulls(train_df)\n",
    "\n",
    "# Split features and target into X and y\n",
    "X, y = train_df.iloc[:,:-1].values, train_df.iloc[:,-1].values\n",
    "\n",
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert train_df into Dmatrix\n",
    "train_set_dmatrix = xgb.DMatrix(X, label=y)\n",
    "\n",
    "# Convert X_train and y_train into Dmatrix\n",
    "train_dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Scale pos weight is sum of neg divided by sum of pos\n",
    "weight = (sum(train_df['target'] == 0)) / (sum(train_df['target'] == 1))\n",
    "\n",
    "# # Setting kfolds for cv\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Hyperparameters - find max depth and min child weight first as they have higher impact\n",
    "cv_params = {\"max_depth\": [3, 5, 7],            # how deep each tree is can grow during any boosting round (~3-10)\n",
    "             \"min_child_weight\": [1, 3, 5]}     # minimum sum of weights (smaller for highly imbalanced class)\n",
    "ind_params = {\"learning_rate\": 0.1,             # step size shrinkage to prevent overfitting (~0-1)\n",
    "              \"n_estimators\": 1000,              # number of trees\n",
    "              \"seed\": 0,                        # for reproducibility\n",
    "              \"subsample\": 0.8,                 # percentage of samples per tree (~0.5-9)\n",
    "              \"colsample_bytree\": 0.8,          # percerntage of features per tree (~0.5-9)\n",
    "              \"objective\": \"binary:logistic\",   # returns predicted probability (or \"reg: logistic\")\n",
    "              \"scale_pos_weight\": weight,       # high class imbalance\n",
    "              \"missing\": -999}                  # xgb can handle missing values\n",
    "\n",
    "# GridSearch evaluates a model with varying parameters to find the best possible combination\n",
    "opt_gbm = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                       cv_params, \n",
    "                       scoring=\"f1\",            # f1 is good in highly imbalanced data with very few true values\n",
    "                       cv=5, \n",
    "                       n_jobs=-1) # use as many threads as possible to build trees in parallel\n",
    "\n",
    "opt_gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt_gbm.predict(X_test)\n",
    "\n",
    "opt_gbm.best_params_                            # finding params for next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - find learning rate and subsample next\n",
    "cv_params = {\"learning_rate\": [0.1, 0.01], \n",
    "             \"subsample\": [0.7, 0.8, 0.9]}\n",
    "ind_params = {\"n_estimators\": 1000, \n",
    "              \"seed\": 0, \n",
    "              \"colsample_bytree\": 0.8, \n",
    "              \"objective\": \"binary:logistic\", \n",
    "              \"max_depth\": 5,                   # chosen as best param\n",
    "              \"min_child_weight\": 5,            # chosen as best param\n",
    "              \"scale_pos_weight\": weight,\n",
    "              \"missing\": -999}\n",
    "\n",
    "opt_gbm = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                       cv_params, \n",
    "                       scoring=\"f1\", \n",
    "                       cv=5, \n",
    "                       n_jobs=-1)\n",
    "\n",
    "opt_gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters - find learning rate and subsample next\n",
    "# cv_params = {\"subsample\": [0.6, 0.7, 0.8, 0.9], \n",
    "#              \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9]}\n",
    "# ind_params = {\"n_estimators\": 100, \n",
    "#               \"seed\": 0, \n",
    "#               \"colsample_bytree\": 0.8, \n",
    "#               \"objective\": \"binary:logistic\", \n",
    "#               \"max_depth\": 3,                   # chosen as best param\n",
    "#               \"min_child_weight\": 3,            # chosen as best param\n",
    "#               \"scale_pos_weight\": weight,\n",
    "#               \"missing\": -999}\n",
    "\n",
    "# opt_gbm = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "#                        cv_params, \n",
    "#                        scoring=\"f1\", \n",
    "#                        cv=kfold, \n",
    "#                        n_jobs=-1)\n",
    "\n",
    "# opt_gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt_gbm.predict(X_test)\n",
    "\n",
    "opt_gbm.best_params_                            # finding params for next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {\"eta\": 0.01,                      # chosen as best param - aka learning rate\n",
    "              \"seed\": 0, \n",
    "              \"subsample\": 0.7,                 # chosen as best param\n",
    "              \"colsample_bytree\": 0.7,          # chosen as best param\n",
    "              \"objective\": \"binary:logistic\", \n",
    "              \"max_depth\": 5, \n",
    "              \"min_child_weight\": 5, \n",
    "              \"scale_pos_weight\": weight,\n",
    "              \"missing\": -999}\n",
    "\n",
    "# CV estimates the preformance of one set of parameter on unseen data\n",
    "cv_xgb = xgb.cv(our_params, \n",
    "                train_dmatrix, \n",
    "                num_boost_round=1000,           # number of trees - aka n_estimators\n",
    "                nfold=5,\n",
    "                metrics=[\"error\"],              # binary classification error rate (0.5 threshold)\n",
    "                stratified=True,\n",
    "                early_stopping_rounds=100)      # finish early if it does not improve for n rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine final boost round\n",
    "cv_xgb.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl = xgb.XGBClassifier(learning_rate=0.01, \n",
    "                          seed=0, \n",
    "                          subsample=0.7, \n",
    "                          colsample_bytree=0.7, \n",
    "                          objective=\"binary:logistic\", \n",
    "                          max_depth=5, \n",
    "                          min_child_weight=5, \n",
    "                          scale_pos_weight=weight, \n",
    "                          n_estimators=54,      # last round from cv\n",
    "                          missing=-999)\n",
    "\n",
    "xg_cl.fit(X_train, y_train)\n",
    "y_pred = xg_cl.predict(X_test)\n",
    "\n",
    "# Let's see how these parameters perform against OOS data\n",
    "# Confusion matrix\n",
    "display(pd.crosstab(y_test, y_pred, rownames=[\"True\"], colnames=[\"Predicted\"], margins=True))\n",
    "\n",
    "# Accuracy\n",
    "accuracy = float(np.sum(y_pred==y_test)) / y_test.shape[0]\n",
    "print(\"accuracy: %f\" % (accuracy*100))\n",
    "\n",
    "final_xgb = xgb.train(our_params, \n",
    "                      train_dmatrix, \n",
    "                      num_boost_round=54)       # last round from cv\n",
    "\n",
    "# Plot feature importance\n",
    "xgb.plot_importance(final_xgb);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our test prediction, we will train our model on entire train dataset\n",
    "final_xgb = xgb.train(our_params, \n",
    "                      train_dmatrix, \n",
    "                      num_boost_round=144)\n",
    "\n",
    "# Convert dataframe into Dmatrix\n",
    "test_set_dmatrix = xgb.DMatrix(test_df.values)\n",
    "\n",
    "# Using out test dataset for prediction\n",
    "y_pred = final_xgb.predict(test_set_dmatrix)\n",
    "\n",
    "# Threshold for converting probability\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "# Save results to csv for submission\n",
    "results_df = pd.DataFrame({\"index\": test_df.index, \"target\": y_pred})\n",
    "results_df.to_csv(\"./data/xgboost.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://cambridgespark.com/getting-started-with-xgboost/\n",
    "https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/\n",
    "https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e\n",
    "https://medium.com/@mateini_12893/doing-xgboost-hyper-parameter-tuning-the-smart-way-part-1-of-2-f6d255a45dde"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
