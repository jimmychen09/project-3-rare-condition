{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read files into dataframe\n",
    "train_df = pd.read_csv(\"./data/health-diagnostics-train.csv\", na_values=[\"#NULL!\"])\n",
    "test_df = pd.read_csv(\"./data/health-diagnostics-test.csv\", na_values=[\"#NULL!\"])\n",
    "# test_sample = pd.read_csv(\"./data/health-diagnostics-test-sample-solution.csv\")\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "# Replace missing values with mode and change objects to integers\n",
    "def replace_nulls(df):\n",
    "    for f in feature_cols:\n",
    "        df[f] = df[f].astype(float)\n",
    "        df[f].fillna(df[f].mode()[0], inplace=True)\n",
    "        df[f] = df[f].astype(int)\n",
    "\n",
    "replace_nulls(test_df)\n",
    "replace_nulls(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domain:**\n",
    "- income - an annual per capita income of a patient\n",
    "- maternal - maternal delivery age\n",
    "- fam-history - a family history\n",
    "- mat-illness-past - a previous maternal illness history\n",
    "- suppl - nutrition and folic acid supplementation\n",
    "- mat-illness - a maternal illness\n",
    "- meds - medication use\n",
    "- env - an environmental exposures of risk factors\n",
    "- lifestyle - an unhealthy lifestyle\n",
    "- target - a congenital disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.shape\n",
    "# train_df.dtypes\n",
    "# train_df.isnull().sum()\n",
    "# train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for f in feature_cols:\n",
    "# #     display(f, train_df[f].value_counts())\n",
    "#     train_df[f].sort_values().value_counts(sort=False).plot(kind=\"bar\")\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- income\n",
    "    - even distribution\n",
    "- maternal\n",
    "    - large mode of 0\n",
    "- fam-history\n",
    "    - large mode of 0\n",
    "- mat-illness-past\n",
    "    - large mode of 0\n",
    "- suppl\n",
    "    - left skewed\n",
    "- mat-illness\n",
    "- meds\n",
    "- env\n",
    "    - has a distribution\n",
    "- lifestyle\n",
    "    - has a distribution, may need to create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shows binary classification (0 or 1), so requires logistic regression\n",
    "- shows there is a class imbalance, very few 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find train to test ratio\n",
    "train_df.shape[0] / (train_df.shape[0]+test_df.shape[0])\n",
    "\n",
    "# Find percentage of 1's\n",
    "round(train_df['target'].sum() / train_df['target'].count() * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shows there is a 90 : 10 split between train : test\n",
    "- therefore, probably very few true predictions\n",
    "- there is there is 0.18% chance of target 1 for every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_mask = train_df['target'] == 1\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "# Find percentage of 1 occuring out of total for each column each category\n",
    "for f in feature_cols:\n",
    "    display(f, train_df[target_mask][f].value_counts(sort=False), train_df[f].value_counts(sort=False),\n",
    "            train_df[target_mask][f].value_counts(sort=False) / train_df[f].value_counts(sort=False) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_rmse(df, feature_cols):\n",
    "#     X = df[feature_cols]\n",
    "#     y = df.target\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    \n",
    "#     linreg = LinearRegression()\n",
    "#     linreg.fit(X_train, y_train)\n",
    "    \n",
    "#     y_pred = linreg.predict(X_test)\n",
    "#     return np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# print(train_test_rmse(train_df, feature_cols, ['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Displaying confusion matrix\n",
    "display(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "recall_metric = round(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1]),0)\n",
    "print(\"Recall metric in the train dataset: {0}%\".format(recall_metric))\n",
    "\n",
    "# Finding the f1 score\n",
    "display(metrics.f1_score(y_test, y_pred, average=\"binary\"))\n",
    "\n",
    "# Predicting on test data\n",
    "test_df['target'] = logreg.predict(test_df[feature_cols])\n",
    "\n",
    "# Saving to csv for submission\n",
    "test_df['target'].to_csv(\"./data/logreg.csv\", index_label=\"index\", header=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.58 AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Feature engineering\n",
    "train_df['low_income'] = train_df['income'] == 1  # higher chance of target\n",
    "train_df['low_suppl'] = train_df['suppl'] < 2  # higher chance of target\n",
    "train_df['mat_ill_cat'] = train_df['mat-illness'] == 2   # higher chance of target\n",
    "lx_dummies = pd.get_dummies(train_df['lifestyle'], prefix=\"lx\")\n",
    "lx_dummies.drop(lx_dummies.columns[0], axis=1, inplace=True)\n",
    "train_df = pd.concat([train_df, lx_dummies], axis=1)\n",
    "\n",
    "feature_cols = ['low_income', 'maternal', 'fam-history', 'mat-illness-past', 'low_suppl', 'mat_ill_cat', \n",
    "                'meds', 'lx_1', 'lx_2', 'lx_3', 'lx_4', 'lx_5', 'lx_6', 'lx_7', 'lx_8']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Displaying confusion matrix\n",
    "display(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "recall_metric = round(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1]),0)\n",
    "print(\"Recall metric in the train dataset: {0}%\".format(recall_metric))\n",
    "\n",
    "metrics.f1_score(y_test, y_pred, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- no improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binary classification with unbalanced data\n",
    "\n",
    "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-106\n",
    "https://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-nearest neighbour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Displaying confusion matrix\n",
    "display(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "# recall_metric = round(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1]),0)\n",
    "# print(\"Recall metric in the train dataset: {0}%\".format(recall_metric))\n",
    "\n",
    "metrics.f1_score(y_test, y_pred, average=\"binary\")\n",
    "\n",
    "# scores = []\n",
    "\n",
    "# for k in range(1,10):\n",
    "#     knn = KNeighborsClassifier(n_neighbors=k)\n",
    "#     knn.fit(X_train, y_train)\n",
    "#     y_pred = knn.predict(X_test)\n",
    "#     scores.append([k, metrics.f1_score(y_test, y_pred, average=\"binary\")])\n",
    "\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntheic Minority Over-sampling Technique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "print(\"Before oversampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before oversampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After oversampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After oversampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "print(\"After oversampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After oversampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "\n",
    "parameters = {\n",
    "    'C': np.linspace(1, 10, 10)\n",
    "             }\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters, cv=5, verbose=5, n_jobs=3)\n",
    "clf.fit(X_train_res, y_train_res.ravel())\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression(C=2, penalty='l1', verbose=5)\n",
    "lr1.fit(X_train_res, y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "y_train_pre = lr1.predict(X_train)\n",
    "\n",
    "cnf_matrix_tra = confusion_matrix(y_train, y_train_pre)\n",
    "\n",
    "print(\"Recall metric in the train dataset: {}%\".format(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1])))\n",
    "\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_tra , classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = lr1.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pre)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: {}%\".format(100*cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1])))\n",
    "#print(\"Precision metric in the testing dataset: {}%\".format(100*cnf_matrix[0,0]/(cnf_matrix[0,0]+cnf_matrix[1,0])))\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix , classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = lr1.fit(X_train_res, y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sample_score = tmp.decision_function(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_sample_score)\n",
    "\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "# Plot ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.3f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1.fit(X_train_res, y_train_res.ravel())\n",
    "\n",
    "# Predicting on test data\n",
    "test_df['target'] = lr1.predict(test_df[feature_cols])\n",
    "\n",
    "# Saving to csv for submission\n",
    "test_df['target'].to_csv(\"./data/logreg_smote.csv\", index_label=\"index\", header=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "feature_cols = ['income', 'maternal', 'fam-history', 'mat-illness-past', 'suppl', 'mat-illness', 'meds', 'env', 'lifestyle']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.target\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "print(\"Before oversampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before oversampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After oversampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After oversampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "print(\"After oversampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After oversampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "\n",
    "parameters = {\n",
    "    'C': np.linspace(1, 10, 10)\n",
    "             }\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "clf = GridSearchCV(lr, parameters, cv=5, verbose=5, n_jobs=3)\n",
    "clf.fit(X_train_res, y_train_res.ravel())\n",
    "\n",
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
